# This script extracts specific sets of instructions generated by the prohow-crawler
# The urls to extract are found in the extract_specific_sets_instructions.txt file
# The extract_specific_sets_instructions.txt file should contain one URL per line
# only the sets of instructions corresponding to these URLs will be extracted
# the URLs will be matched in a non-case sensitive way

## IN-CODE PARAMETERS

# This parameter can be changed to only select instructions with specific language tags.
# More specifically, the algorighm will only consider files having a name which starts with at least one 
list_of_allowed_languages = []
# for example, for English and Spanish: 
# list_of_allowed_languages = ["en","es"]

# This parameter can be changed to only select instructions witin specific categories.
# More specifically, the algorighm will select all the instructions which directly belong to one of the types
# in list_of_allowed_categories, or one their sub-classes as defined in RDFS, in the Turtle file class_hierarchy.ttl
list_of_allowed_categories = []
# for example, the following configuration extracts only breakfast food instructions in Spanish and English
# list_of_allowed_categories = ["http://www.wikihow.com/Category:Breakfast","http://es.wikihow.com/Categor%C3%ADa:Desayunos"]

# CODE START

import os, ntpath, string

hierarchy = {}
# load hieararchy if present
if os.path.isfile("class_hierarchy.ttl"):
    print "Loading a class hierarchy"
    num = 0
    h = open("class_hierarchy.ttl",'r')
    for line in h:
        urls = line.split("> rdfs:subClassOf <")
        #print urls
        url1 = urls[0][1:]
        url2 = urls[1][:-4]
        #print url1
        #print url2
        hierarchy[url1] = url2
        num += 1
    h.close()
    print str(num)+" sub-class relations extracted."

def is_subclass_of(concept,super):
    return is_subclass_of_with_recursion_limit(concept,super,0)

def is_subclass_of_with_recursion_limit(concept,super,level):
    if level > 30:
        return False
    if concept == super:
        return True
    if concept in hierarchy:
        return is_subclass_of_with_recursion_limit(hierarchy[concept],super,level+1)
    return False

list_of_urls = []
conf = open("extract_specific_sets_instructions.txt",'r')
for line in conf:
    extracted = line.lower().strip()
    if len(extracted) > 0:
        list_of_urls.append(extracted);
conf.close()

print "Specific URL extraction configured with: "+str(len(list_of_urls))+" URLs"
	


out = open('graph.ttl','w')

out.write("@prefix w: <http://w3id.org/prohowlinks#> .\n@prefix oa: <http://www.w3.org/ns/oa#> .\n@prefix prohow: <http://w3id.org/prohow#> .\n\
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n\
@prefix owl: <http://www.w3.org/2002/07/owl#> .\n@prefix dbo: <http://dbpedia.org/ontology/> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n")
def save(line):
    out.write(line+"\n\n")

def parse_file(file):
    print "Parsing file "+str(file)
    f = open(file,'r')
    full_instruction = ""	
    found = False
    found_num = 0
    for line in f:
        if 'oa:hasTarget <' in line:
            for url in list_of_urls:
                if "<"+str(url.lower())+">" in line.lower():
                    found = True
        if "rdf:type <" in line:
            line_parts = line.split("rdf:type <")
            type = line_parts[1][:-4]
            for allowed_concept in list_of_allowed_categories:
                if is_subclass_of(type,allowed_concept):
                    found = True
        #if 'http://www.wikihow.com/Category:Cocktails' in line or ('http://es.wikihow.com/Categor%C3%ADa:Bebidas-alcoh%C3%B3licas' in line)\
        #        or ('http://es.wikihow.com/Categor%C3%ADa:Pizza' in line) or ('http://www.wikihow.com/Category:Pizza' in line):
        #    found = True
        if 'rdf:type prohow:instruction_set .' in line:
            # if the previous instruction set was selected, save it in output
            if found:
                save(full_instruction)
                found_num += 1
            # start collecting a new instructions set
            found = False
            full_instruction = line
        else:
            if len(full_instruction) > 0:
                if "<" in line and ">" in line and ":" in line and "http:" in line:
                    line = string.replace(line, "(", "")#tring.replace(s, old, new[, maxreplace])
                    line = string.replace(line, ")", "")
                full_instruction = full_instruction+line
    if found:
        save(full_instruction)
        found_num += 1
    f.close()
    print "Found in file: "+str(found_num)
    return found_num


rootdir = os.getcwd()
total_found = 0
for subdir, dirs, files in os.walk(rootdir):
    for file in files:
        #print os.path.join(subdir, file)
        filepath = subdir + os.sep + file
        if filepath.endswith(".ttl"):
            if len(list_of_allowed_languages) > 0:
                for lang in list_of_allowed_languages:
                    if ntpath.basename(filepath).startswith(lang):
                        print filepath
                        total_found += parse_file(filepath)
            else:
                total_found += parse_file(filepath)
out.close()

print 'In total, '+str(total_found)+' were found'
